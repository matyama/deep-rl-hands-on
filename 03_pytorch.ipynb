{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "parental-bikini",
   "metadata": {},
   "source": [
    "# Deep Learning with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "delayed-armor",
   "metadata": {},
   "source": [
    "## Tensors\n",
    "*Tensors* represent\n",
    "* *multilinear maps* between vector spaces (mathematics)\n",
    "* generic *n-dimensional arrays* (computer science)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "raised-fleet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3556e-19, 3.0097e+29],\n",
       "        [7.1853e+22, 4.5145e+27],\n",
       "        [1.8040e+28, 1.5769e-19]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Create an uninitialized 3x2 tensor of 32-bit floats\n",
    "a = torch.FloatTensor(3, 2)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "color-evolution",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the tensor (in-place) with zeros\n",
    "a.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naughty-macro",
   "metadata": {},
   "source": [
    "There are two types of methods in the PyTorch API:\n",
    "* Functional ones that return transformed copies have standard names like `some_function()`\n",
    "* In-place mutating operations will have a trailing underscore in their name, e.g. `some_function_()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "recent-wells",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [3., 2., 1.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor from a standard collection\n",
    "torch.FloatTensor([[1, 2, 3], [3, 2, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "boring-graph",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = np.zeros(shape=(3, 2))\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "smart-marshall",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor from a numpy ndarray\n",
    "b = torch.tensor(n)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "developing-alberta",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the numpy array to 64-bit float\n",
    "#  - This translates to the tensor\n",
    "n = np.zeros(shape=(3, 2), dtype=np.float32)\n",
    "torch.tensor(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "developed-nutrition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternatively specify a PyTorch dtype\n",
    "n = np.zeros(shape=(3, 2))\n",
    "torch.tensor(n, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "funky-poetry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1, 2, 3])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "usual-somerset",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scalar tensors can be results of some aggregations\n",
    "s = a.sum()\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dental-accommodation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There's a convenient method to access the value of a scalar tensor\n",
    "s.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "attractive-vehicle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(42)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "korean-chest",
   "metadata": {},
   "source": [
    "### Tensor Operations\n",
    "Each tensor has associated `device` where the computation takes place. The options are\n",
    "* `cpu` - computation takes place on the CPU\n",
    "* `cuda` or `cuda:<index>` - computation takes place on the GPU (with a device id `<index>`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "nasty-quality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 3.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine computation device based on CUDA availability\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "a = torch.FloatTensor([2, 3])\n",
    "\n",
    "# Move the tensor to GPU (if there's CUDA available)\n",
    "a = a.to(device)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "italic-productivity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "soviet-appearance",
   "metadata": {},
   "source": [
    "### Tensors and Gradients\n",
    "Each tensor has following info related to automatic gradient computation:\n",
    "* `grad` is a property holding computed gradients (tensor of the same shape)\n",
    "* `is_leaf` is true if the tensor was constructed by a user and false if it's a result of a computation\n",
    "* `requires_grad` is true if the tensor requires gradients to be computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "southern-powder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define some tensors\n",
    "#  - The first one requires gradients to be computed\n",
    "v1 = torch.tensor([1.0, 1.0], requires_grad=True)\n",
    "v2 = torch.tensor([2.0, 2.0])\n",
    "\n",
    "# Define a computational graph on these tensors\n",
    "#  - Notice: Result contains a function coputing the gradient.\n",
    "v_sum = v1 + v2\n",
    "v_res = (v_sum * 2).sum()\n",
    "v_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dimensional-intake",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1.is_leaf, v2.is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "arranged-tiger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_sum.is_leaf, v_res.is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "identified-consciousness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1.requires_grad, v2.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "blank-poultry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_sum.requires_grad, v_res.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "legal-inside",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the gradients of our graph\n",
    "v_res.backward()\n",
    "\n",
    "# Show backpropagated gradients in v1\n",
    "v1.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "chinese-buffer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2 does not require any gradients so there's nothing\n",
    "v2.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "communist-recycling",
   "metadata": {},
   "source": [
    "## Neural Network Building Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "through-uruguay",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.1789, -0.4192, -0.8343, -1.2979, -0.6996], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn  # noqa\n",
    "\n",
    "# Construct a 2-to-5 dense layer with an implicit bias\n",
    "#  - Note: Weights of this layer are randomly initialized.\n",
    "dense = nn.Linear(2, 5)\n",
    "\n",
    "# Each PyTorch NN module acts as a callable\n",
    "inputs = torch.FloatTensor([1, 2])\n",
    "dense(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convertible-cookbook",
   "metadata": {},
   "source": [
    "Some important methods from PyTorch API:\n",
    "* `parameters()` returns an iterable of all trainable variables (those that require gradients)\n",
    "* `zero_grad()` initializes all gradients to zero\n",
    "* `to(device)` moves the computation to a device\n",
    "* `state_dict()` exports all weights to a dictionary for model serialization\n",
    "* `load_state_dict()` oppisite of the previous which imports weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "conventional-indianapolis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2, out_features=5, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=5, out_features=20, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=20, out_features=10, bias=True)\n",
       "  (5): ReLU()\n",
       "  (6): Dropout(p=0.3, inplace=False)\n",
       "  (7): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a sequential model with\n",
    "#  - Three dense layers with ReLU activations\n",
    "#  - A dropout layer\n",
    "#  - And a softmax output over the feature dimension\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(2, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(5, 20),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.3),\n",
    "    nn.Softmax(dim=1),\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "biological-reserve",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0937, 0.1025, 0.0937, 0.1092, 0.0937, 0.0937, 0.1323, 0.0937, 0.0937,\n",
       "         0.0937]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feed an input tensor through our sequential model\n",
    "#  - There's single instance in the input batch\n",
    "model(torch.FloatTensor([[1, 2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "under-brush",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
