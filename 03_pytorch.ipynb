{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "raising-evanescence",
   "metadata": {},
   "source": [
    "# Deep Learning with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical-spoke",
   "metadata": {},
   "source": [
    "## Tensors\n",
    "*Tensors* represent\n",
    "* *multilinear maps* between vector spaces (mathematics)\n",
    "* generic *n-dimensional arrays* (computer science)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "comfortable-parent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3556e-19, 3.0097e+29],\n",
       "        [7.1853e+22, 4.5145e+27],\n",
       "        [1.8040e+28, 1.5769e-19]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Create an uninitialized 3x2 tensor of 32-bit floats\n",
    "a = torch.FloatTensor(3, 2)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "purple-belgium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the tensor (in-place) with zeros\n",
    "a.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-yahoo",
   "metadata": {},
   "source": [
    "There are two types of methods in the PyTorch API:\n",
    "* Functional ones that return transformed copies have standard names like `some_function()`\n",
    "* In-place mutating operations will have a trailing underscore in their name, e.g. `some_function_()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "impressed-conspiracy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [3., 2., 1.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor from a standard collection\n",
    "torch.FloatTensor([[1, 2, 3], [3, 2, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "smart-story",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = np.zeros(shape=(3, 2))\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "billion-fantasy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor from a numpy ndarray\n",
    "b = torch.tensor(n)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "romance-creature",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the numpy array to 64-bit float\n",
    "#  - This translates to the tensor\n",
    "n = np.zeros(shape=(3, 2), dtype=np.float32)\n",
    "torch.tensor(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "federal-wichita",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternatively specify a PyTorch dtype\n",
    "n = np.zeros(shape=(3, 2))\n",
    "torch.tensor(n, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "featured-temple",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1, 2, 3])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "threatened-british",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scalar tensors can be results of some aggregations\n",
    "s = a.sum()\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "perceived-standing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There's a convenient method to access the value of a scalar tensor\n",
    "s.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "above-yemen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(42)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-surgery",
   "metadata": {},
   "source": [
    "### Tensor Operations\n",
    "Each tensor has associated `device` where the computation takes place. The options are\n",
    "* `cpu` - computation takes place on the CPU\n",
    "* `cuda` or `cuda:<index>` - computation takes place on the GPU (with a device id `<index>`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "binding-provision",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 3.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine computation device based on CUDA availability\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "a = torch.FloatTensor([2, 3])\n",
    "\n",
    "# Move the tensor to GPU (if there's CUDA available)\n",
    "a = a.to(device)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "wound-instrumentation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-dispute",
   "metadata": {},
   "source": [
    "### Tensors and Gradients\n",
    "Each tensor has following info related to automatic gradient computation:\n",
    "* `grad` is a property holding computed gradients (tensor of the same shape)\n",
    "* `is_leaf` is true if the tensor was constructed by a user and false if it's a result of a computation\n",
    "* `requires_grad` is true if the tensor requires gradients to be computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "headed-binary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define some tensors\n",
    "#  - The first one requires gradients to be computed\n",
    "v1 = torch.tensor([1.0, 1.0], requires_grad=True)\n",
    "v2 = torch.tensor([2.0, 2.0])\n",
    "\n",
    "# Define a computational graph on these tensors\n",
    "#  - Notice: Result contains a function coputing the gradient.\n",
    "v_sum = v1 + v2\n",
    "v_res = (v_sum * 2).sum()\n",
    "v_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cutting-assets",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1.is_leaf, v2.is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "improving-disease",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_sum.is_leaf, v_res.is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "narrative-double",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1.requires_grad, v2.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "muslim-banks",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_sum.requires_grad, v_res.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "hungry-donor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the gradients of our graph\n",
    "v_res.backward()\n",
    "\n",
    "# Show backpropagated gradients in v1\n",
    "v1.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "armed-stylus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v2 does not require any gradients so there's nothing\n",
    "v2.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removed-vegetable",
   "metadata": {},
   "source": [
    "## Neural Network Building Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dangerous-currency",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2939, -1.2834,  0.0977,  1.6714,  0.0031], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn  # noqa\n",
    "\n",
    "# Construct a 2-to-5 dense layer with an implicit bias\n",
    "#  - Note: Weights of this layer are randomly initialized.\n",
    "dense = nn.Linear(2, 5)\n",
    "\n",
    "# Each PyTorch NN module acts as a callable\n",
    "inputs = torch.FloatTensor([1, 2])\n",
    "dense(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exciting-swaziland",
   "metadata": {},
   "source": [
    "Some important methods from PyTorch API:\n",
    "* `parameters()` returns an iterable of all trainable variables (those that require gradients)\n",
    "* `zero_grad()` initializes all gradients to zero\n",
    "* `to(device)` moves the computation to a device\n",
    "* `state_dict()` exports all weights to a dictionary for model serialization\n",
    "* `load_state_dict()` oppisite of the previous which imports weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "scenic-gothic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2, out_features=5, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=5, out_features=20, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=20, out_features=10, bias=True)\n",
       "  (5): ReLU()\n",
       "  (6): Dropout(p=0.3, inplace=False)\n",
       "  (7): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a sequential model with\n",
    "#  - Three dense layers with ReLU activations\n",
    "#  - A dropout layer\n",
    "#  - And a softmax output over the feature dimension\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(2, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(5, 20),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.3),\n",
    "    nn.Softmax(dim=1),\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "accomplished-investigator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1137, 0.0886, 0.1400, 0.1144, 0.0886, 0.0886, 0.0886, 0.0886, 0.0886,\n",
       "         0.1005]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feed an input tensor through our sequential model\n",
    "#  - There's single instance in the input batch\n",
    "model(torch.FloatTensor([[1, 2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wanted-rider",
   "metadata": {},
   "source": [
    "### Custom Layers\n",
    "Creating custom modules (layers) is as easy as inheriting from `nn.Module` class and implementing the `forward()` method. Every other instance of a module assigned to a field is automatically registered under this module.\n",
    "\n",
    "Note that the convention is to use the module as a callable - this is because the `Module` class does some extra work in the `__call__` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "hired-stamp",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyModule(\n",
       "  (pipe): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=5, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=5, out_features=20, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=20, out_features=3, bias=True)\n",
       "    (5): Dropout(p=0.3, inplace=False)\n",
       "    (6): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import TypeVar  # noqa\n",
    "\n",
    "T = TypeVar(\"T\", bound=torch.Tensor)\n",
    "\n",
    "\n",
    "class MyModule(nn.Module):\n",
    "    \"\"\"Custom PyTorch module\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_inputs: int,\n",
    "        n_outputs: int,\n",
    "        dropout_prob: float = 0.3,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        # Build a sequential model\n",
    "        #  - Every field that is a Module is auto-discovered\n",
    "        self.pipe = nn.Sequential(\n",
    "            nn.Linear(n_inputs, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, n_outputs),\n",
    "            nn.Dropout(p=dropout_prob),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: T) -> T:\n",
    "        # We must treat the sub-module as a callable!\n",
    "        return self.pipe(x)\n",
    "\n",
    "\n",
    "# Build an instance of this model and show its structure\n",
    "net = MyModule(n_inputs=2, n_outputs=3)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "innocent-struggle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3075, 0.3657, 0.3268]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feed an input batch to the model\n",
    "net(torch.FloatTensor([[2, 3]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detailed-milwaukee",
   "metadata": {},
   "source": [
    "### Loss Functions and Optimizers\n",
    "\n",
    "PyTorch includes standard set of loss functions and of course allows simple implementation of custom ones. Here's a short list of some loss function classes:\n",
    "* `nn.MSELoss` is the *mean squared error* typically used for regression problems\n",
    "* `nn.BCELoss` and `BCEWithLogits` are *binary cross-entropy* losses for binary classification problems - the former expects single probability value while the latter raw scores (usually preferable)\n",
    "* `nn.CrossEntropyLoss` and `nn.NLLLoss` for multi-class classification problems\n",
    "\n",
    "Similarly there is buch of traditional optimizers such as vanilla `SGD`, `RMSprop`, `Adagrad` or the popular `Adam`. Finally, here's a typical training loop in PyTorch.\n",
    "```python\n",
    "# Define model and loss function\n",
    "model = ...\n",
    "loss_fn = ...\n",
    "\n",
    "# Register all trainable parameters in an optimizer\n",
    "optimizer = optim.Adam(params=model.parameters(), ...)\n",
    "\n",
    "# Iterate over mini-batches of training data\n",
    "for X_train, y_trian in iterate_batches(data, batch_size=32)\n",
    "    \n",
    "    # Wrap examples and labels into tensors\n",
    "    X_train = torch.tensor(X_train)\n",
    "    y_trian = torch.tensor(y_trian)\n",
    "    \n",
    "    # Make predictions using the model\n",
    "    y_pred = model(X_train)\n",
    "    \n",
    "    # Compute model's prediction loss\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    \n",
    "    # Compute gradients of the loss function w.r.t. all the weights\n",
    "    #  - The loss is just a computation graph over tensors in the model\n",
    "    #  - And because model's weights \"require gradients\" this calculates dL/dw\n",
    "    loss.backward()\n",
    "    \n",
    "    # Perform one gradient descent step using computed gradients\n",
    "    #  - Note: The optimizer has access to `grad` for registered `params`\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Clear gradients for this step\n",
    "    #  - Alternatively this can be done as the beginning of a step\n",
    "    #  - Note: This is a convenience method for calling it on the model\n",
    "    optimizer.zero_grad()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "logical-spirit",
   "metadata": {},
   "source": [
    "## Monitoring with TensorBoard(X)\n",
    "Following example shows how to log arbitrary metrics and investigate them with *TensorBoard*. Because TensorBoard expects data in *TensorFlow* format we use `tensorboardX` for easy integration (also because it's a dependecy of PyTorch Ignite that we'll use later).\n",
    "\n",
    "Example below computes values of few trigonometric functions for varying angles and stores the output in `runs/` director. For later view one can run TensorBoard with\n",
    "```bash\n",
    "tensorboard --log-dir runs\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "expanded-career",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math  # noqa\n",
    "\n",
    "from tensorboardX import SummaryWriter  # noqa\n",
    "\n",
    "# Define some functions representing our metrics\n",
    "funcs = {\"sin\": math.sin, \"cos\": math.cos, \"tan\": math.tan}\n",
    "\n",
    "# Create tesorboardX writer\n",
    "#  - Note: The default output directory is './runs'\n",
    "#  - Note 2: By default each call creates new \"run\"\n",
    "with SummaryWriter() as writer:\n",
    "\n",
    "    # Register one metric per function\n",
    "    for name, f in funcs.items():\n",
    "\n",
    "        # Evaluate and record f on interval [-360, 360)\n",
    "        for angle in range(-360, 360):\n",
    "            val = f(angle * math.pi / 180)\n",
    "            writer.add_scalar(name, val, angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "collective-words",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mruns\u001b[00m\n",
      "├── \u001b[01;34mMar10_17-31-44_mpc-xps\u001b[00m\n",
      "│   └── events.out.tfevents.1615393904.mpc-xps\n",
      "└── \u001b[01;34mMar10_17-31-47_mpc-xps\u001b[00m\n",
      "    └── events.out.tfevents.1615393907.mpc-xps\n",
      "\n",
      "2 directories, 2 files\n"
     ]
    }
   ],
   "source": [
    "!tree runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatty-sensitivity",
   "metadata": {},
   "source": [
    "## GAN on Atari Images\n",
    "Let's train a *Generative Adversarial Network (GAN)* on randomly sampled screenshots from three Atari games and collect training metrics for TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "thirty-freedom",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "neural-judges",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random  # noqa\n",
    "from typing import Any, Iterable, Sequence, Tuple  # noqa\n",
    "\n",
    "import cv2  # noqa\n",
    "import gym  # noqa\n",
    "import torch.optim as optim  # noqa\n",
    "import torchvision.utils as vutils  # noqa\n",
    "\n",
    "# Hyperparameters\n",
    "IMAGE_SIZE = 64\n",
    "LATENT_VECTOR_SIZE = 100\n",
    "DISCR_FILTERS = 64\n",
    "GENER_FILTERS = 64\n",
    "BATCH_SIZE = 16\n",
    "MAX_ITERS = 2_000\n",
    "LEARNING_RATE = 0.0001\n",
    "REPORT_PERIOD = 100\n",
    "SAVE_IMAGE_PERIOD = 1000\n",
    "\n",
    "\n",
    "class InputWrapper(gym.ObservationWrapper):\n",
    "    \"\"\"\n",
    "    Preprocessing of input numpy array:\n",
    "    1. resize image into predefined size\n",
    "    2. move color channel axis to a first place\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args: Any) -> None:\n",
    "        super().__init__(*args)\n",
    "        assert isinstance(self.observation_space, gym.spaces.Box)\n",
    "        box = self.observation_space\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            self.observation(box.low),\n",
    "            self.observation(box.high),\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "\n",
    "    def observation(self, observation: np.ndarray) -> np.ndarray:\n",
    "        # Resize the image\n",
    "        new_obs = cv2.resize(observation, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "        # Move the color dimension to the fromt\n",
    "        #  - PyTorch's conv. layers expect shape [channels, width, height]\n",
    "        new_obs = np.moveaxis(new_obs, 2, 0)\n",
    "        return new_obs.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "passive-cursor",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    Converts an image into single number\n",
    "    representing the probability of positive class\n",
    "    (the image being real).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_shape: Tuple[int, ...]) -> None:\n",
    "        super().__init__()\n",
    "        self.conv_pipe = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=input_shape[0],\n",
    "                out_channels=DISCR_FILTERS,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels=DISCR_FILTERS,\n",
    "                out_channels=DISCR_FILTERS * 2,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.BatchNorm2d(DISCR_FILTERS * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels=DISCR_FILTERS * 2,\n",
    "                out_channels=DISCR_FILTERS * 4,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.BatchNorm2d(DISCR_FILTERS * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels=DISCR_FILTERS * 4,\n",
    "                out_channels=DISCR_FILTERS * 8,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.BatchNorm2d(DISCR_FILTERS * 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                in_channels=DISCR_FILTERS * 8,\n",
    "                out_channels=1,\n",
    "                kernel_size=4,\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "            ),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: T) -> T:\n",
    "        conv_out = self.conv_pipe(x)\n",
    "        return conv_out.view(-1, 1).squeeze(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "private-buying",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\"Deconvolves input vector into 3x64x64 image\"\"\"\n",
    "\n",
    "    def __init__(self, output_shape: Tuple[int, ...]) -> None:\n",
    "        super().__init__()\n",
    "        self.pipe = nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=LATENT_VECTOR_SIZE,\n",
    "                out_channels=GENER_FILTERS * 8,\n",
    "                kernel_size=4,\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "            ),\n",
    "            nn.BatchNorm2d(GENER_FILTERS * 8),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=GENER_FILTERS * 8,\n",
    "                out_channels=GENER_FILTERS * 4,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.BatchNorm2d(GENER_FILTERS * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=GENER_FILTERS * 4,\n",
    "                out_channels=GENER_FILTERS * 2,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.BatchNorm2d(GENER_FILTERS * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=GENER_FILTERS * 2,\n",
    "                out_channels=GENER_FILTERS,\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.BatchNorm2d(GENER_FILTERS),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=GENER_FILTERS,\n",
    "                out_channels=output_shape[0],\n",
    "                kernel_size=4,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: T) -> T:\n",
    "        return self.pipe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "diagnostic-vegetable",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1/2000 Loss (generator): 1.674 Loss (discriminator): 1.277\n",
      "Iter: 101/2000 Loss (generator): 5.527 Loss (discriminator): 0.039\n",
      "Iter: 201/2000 Loss (generator): 7.124 Loss (discriminator): 0.004\n",
      "Iter: 301/2000 Loss (generator): 7.540 Loss (discriminator): 0.002\n",
      "Iter: 401/2000 Loss (generator): 7.829 Loss (discriminator): 0.001\n",
      "Iter: 501/2000 Loss (generator): 8.007 Loss (discriminator): 0.197\n",
      "Iter: 601/2000 Loss (generator): 7.070 Loss (discriminator): 0.012\n",
      "Iter: 701/2000 Loss (generator): 9.209 Loss (discriminator): 0.013\n",
      "Iter: 801/2000 Loss (generator): 6.713 Loss (discriminator): 0.004\n",
      "Iter: 901/2000 Loss (generator): 8.270 Loss (discriminator): 0.081\n",
      "Iter: 1001/2000 Loss (generator): 6.971 Loss (discriminator): 0.009\n",
      "Iter: 1101/2000 Loss (generator): 6.687 Loss (discriminator): 0.004\n",
      "Iter: 1201/2000 Loss (generator): 7.265 Loss (discriminator): 0.002\n",
      "Iter: 1301/2000 Loss (generator): 8.469 Loss (discriminator): 0.072\n",
      "Iter: 1401/2000 Loss (generator): 6.003 Loss (discriminator): 0.014\n",
      "Iter: 1501/2000 Loss (generator): 6.528 Loss (discriminator): 0.005\n",
      "Iter: 1601/2000 Loss (generator): 8.635 Loss (discriminator): 0.056\n",
      "Iter: 1701/2000 Loss (generator): 6.476 Loss (discriminator): 0.006\n",
      "Iter: 1801/2000 Loss (generator): 6.488 Loss (discriminator): 0.108\n",
      "Iter: 1901/2000 Loss (generator): 5.856 Loss (discriminator): 0.011\n"
     ]
    }
   ],
   "source": [
    "def iterate_batches(\n",
    "    envs: Sequence[gym.Env],\n",
    "    batch_size: int = BATCH_SIZE,\n",
    ") -> Iterable[T]:\n",
    "    # Initialize a buffer for current batch\n",
    "    batch = [e.reset() for e in envs]\n",
    "\n",
    "    # Create a sampler over the environments\n",
    "    env_sampler = iter(lambda: random.choice(envs), None)\n",
    "\n",
    "    while True:\n",
    "\n",
    "        # Sample an action from random environment\n",
    "        env = next(env_sampler)\n",
    "        action = env.action_space.sample()\n",
    "\n",
    "        # Get new observation for the action\n",
    "        obs, _, done, _ = env.step(action)\n",
    "\n",
    "        # Just a hack to fix one of the envs\n",
    "        if np.mean(obs) > 0.01:\n",
    "            batch.append(obs)\n",
    "\n",
    "        # Generate new batch\n",
    "        #  - Normalize values to [-1, 1]\n",
    "        #  - Yield new tensor and clean the buffer\n",
    "        if len(batch) == batch_size:\n",
    "            norm_batch = np.array(batch, dtype=np.float32) * 2.0 / 255.0 - 1.0\n",
    "            yield torch.tensor(norm_batch)\n",
    "            batch.clear()\n",
    "\n",
    "        # Restart environment when episode ends\n",
    "        if done:\n",
    "            env.reset()\n",
    "\n",
    "\n",
    "# Create new gym environments for 3 Atari games\n",
    "envs = [\n",
    "    InputWrapper(gym.make(name))\n",
    "    for name in ('Breakout-v0', 'AirRaid-v0', 'Pong-v0')\n",
    "]\n",
    "\n",
    "input_shape = envs[0].observation_space.shape\n",
    "\n",
    "# Create GAN components\n",
    "discriminator = Discriminator(input_shape=input_shape).to(device)\n",
    "generator = Generator(output_shape=input_shape).to(device)\n",
    "\n",
    "# The objective is binary cross-entropy (binary classification)\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "# Create two optimizers - one for each component\n",
    "gen_optimizer = optim.Adam(\n",
    "    params=generator.parameters(),\n",
    "    lr=LEARNING_RATE,\n",
    "    betas=(0.5, 0.999),\n",
    ")\n",
    "\n",
    "dis_optimizer = optim.Adam(\n",
    "    params=discriminator.parameters(),\n",
    "    lr=LEARNING_RATE,\n",
    "    betas=(0.5, 0.999),\n",
    ")\n",
    "\n",
    "# Create labels for true and fake images\n",
    "true_labels = torch.ones(BATCH_SIZE, device=device)\n",
    "fake_labels = torch.zeros(BATCH_SIZE, device=device)\n",
    "\n",
    "# Start recording of the training metrics for TensorBoard\n",
    "with SummaryWriter() as writer:\n",
    "\n",
    "    gen_losses = []\n",
    "    dis_losses = []\n",
    "\n",
    "    batch_iter = iter(iterate_batches(envs))\n",
    "\n",
    "    # Main training loop\n",
    "    for i in range(MAX_ITERS):\n",
    "        real_inputs = next(batch_iter)\n",
    "\n",
    "        # Move the input batch to selected device\n",
    "        real_inputs = real_inputs.to(device)\n",
    "\n",
    "        # Generate an equal-sized batch of codings for fake images\n",
    "        #  - Latent vectors are drawn from N(0, 1)\n",
    "        #  - And we move them to selected device too\n",
    "        codings = torch.FloatTensor(BATCH_SIZE, LATENT_VECTOR_SIZE, 1, 1)\n",
    "        codings.normal_(0, 1)\n",
    "        codings = codings.to(device)\n",
    "\n",
    "        # Generate fake images using the generator\n",
    "        fake_inputs = generator(codings)\n",
    "\n",
    "        # Train the discriminator\n",
    "        #  - Note: We must `detach` generator inputs to not alter its weights\n",
    "        dis_optimizer.zero_grad()\n",
    "        pred_true = discriminator(real_inputs)\n",
    "        pred_fake = discriminator(fake_inputs.detach())\n",
    "        dis_loss = loss_fn(pred_true, true_labels) + loss_fn(\n",
    "            pred_fake, fake_labels\n",
    "        )\n",
    "        dis_loss.backward()\n",
    "        dis_optimizer.step()\n",
    "        dis_losses.append(dis_loss.item())\n",
    "\n",
    "        # Train the generator\n",
    "        gen_optimizer.zero_grad()\n",
    "        dis_pred = discriminator(fake_inputs)\n",
    "        gen_loss = loss_fn(dis_pred, true_labels)\n",
    "        gen_loss.backward()\n",
    "        gen_optimizer.step()\n",
    "        gen_losses.append(gen_loss.item())\n",
    "\n",
    "        # Collect training metrics\n",
    "        if i % REPORT_PERIOD == 0:\n",
    "\n",
    "            # Compute mean losses over buffered window\n",
    "            mean_gen_loss = np.mean(gen_losses)\n",
    "            mean_dis_loss = np.mean(dis_losses)\n",
    "\n",
    "            print(\n",
    "                f\"Iter: {i + 1}/{MAX_ITERS}\",\n",
    "                \"Loss (generator):\",\n",
    "                f\"{mean_gen_loss:.3f}\",\n",
    "                \"Loss (discriminator):\",\n",
    "                f\"{mean_dis_loss:.3f}\",\n",
    "            )\n",
    "\n",
    "            writer.add_scalar(\"mean_gen_loss\", mean_gen_loss, i)\n",
    "            writer.add_scalar(\"mean_dis_loss\", mean_dis_loss, i)\n",
    "\n",
    "            # Reset the loss buffers\n",
    "            gen_losses = []\n",
    "            dis_losses = []\n",
    "\n",
    "        # Collect real and fake images\n",
    "        if i % SAVE_IMAGE_PERIOD == 0:\n",
    "            real_img = vutils.make_grid(real_inputs.data[:64], normalize=True)\n",
    "            fake_img = vutils.make_grid(fake_inputs.data[:64], normalize=True)\n",
    "            writer.add_image(\"real\", real_img, i)\n",
    "            writer.add_image(\"fake\", fake_img, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpreted-money",
   "metadata": {},
   "source": [
    "Not great but we've trained the GAN for just few iterations (2k) and it suffices as an example. Now, let's re-implement this using a higher-level library called *PyTorch Ignite*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contained-acceptance",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
